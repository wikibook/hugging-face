{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install faiss-gpu\n",
    "# !conda install -c pytorch faiss-gpu\n",
    "!pip3 install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs[\"pixel_values\"])\n",
    "\n",
    "print(\"마지막 특징 맵의 형태 :\", outputs[\"last_hidden_state\"].shape)\n",
    "print(\"특징 벡터의 차원 수 :\", outputs[\"last_hidden_state\"][:, 0, :].shape)\n",
    "print(\"특징 벡터 :\", outputs[\"last_hidden_state\"][:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3977dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "dataset = load_dataset(\"sasha/dog-food\")\n",
    "images = dataset[\"test\"][\"image\"][:100]\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "\n",
    "vectors = []\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        inputs = processor(images=image, padding=True, return_tensors=\"pt\")\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "        vectors.append(outputs.cpu().numpy())\n",
    "\n",
    "vectors = np.vstack(vectors)\n",
    "print(\"이미지 벡터의 shape :\", vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = vectors.shape[-1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "if torch.cuda.is_available():\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "\n",
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b954c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "search_vector = vectors[0].reshape(1, -1)\n",
    "num_neighbors = 5\n",
    "distances, indices = index.search(x=search_vector, k=num_neighbors)\n",
    "\n",
    "fig, axes = plt.subplots(1, num_neighbors + 1, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(images[0])\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    axes[i + 1].imshow(images[idx])\n",
    "    axes[i + 1].set_title(f\"Match {i + 1}\\nIndex: {idx}\\nDist: {distances[0][i]:.2f}\")\n",
    "    axes[i + 1].axis(\"off\")\n",
    "\n",
    "print(\"유사한 벡터의 인덱스 번호:\", indices)\n",
    "print(\"유사도 계산 결과:\", distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
