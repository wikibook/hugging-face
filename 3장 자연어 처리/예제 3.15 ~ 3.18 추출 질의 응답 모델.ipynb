{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce77ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizerFast, RobertaForQuestionAnswering\n",
    "\n",
    "def preprocess_data(example, tokenizer):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    start_index = example[\"answers\"][\"answer_start\"][0]\n",
    "    answer_text = example[\"answers\"][\"text\"][0]\n",
    "    answer_tokens = tokenizer.encode(answer_text, add_special_tokens=False)\n",
    "    answer_tokens_length = len(answer_tokens)\n",
    "\n",
    "    start_context_tokens_index = tokenized[\"input_ids\"].index(tokenizer.sep_token_id)\n",
    "    context_offset_mapping = tokenized[\"offset_mapping\"][start_context_tokens_index:]\n",
    "    tokenized[\"start_positions\"] = len(tokenized[\"input_ids\"])\n",
    "    tokenized[\"end_positions\"] = len(tokenized[\"input_ids\"])\n",
    "    \n",
    "    for i, (start_offset, end_offset) in enumerate(context_offset_mapping):\n",
    "        if start_offset >= start_index:\n",
    "            tokenized[\"start_positions\"] = start_context_tokens_index + i\n",
    "            tokenized[\"end_positions\"] = tokenized[\"start_positions\"] + answer_tokens_length\n",
    "            break\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "model_name = \"klue/roberta-base\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "model = RobertaForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "dataset = load_dataset(\"klue\", \"mrc\")\n",
    "processed_dataset = dataset.filter(lambda x: not x[\"is_impossible\"])\n",
    "processed_dataset = processed_dataset.map(\n",
    "    lambda example: preprocess_data(example, tokenizer), batched=False\n",
    ")\n",
    "processed_dataset = processed_dataset.filter(\n",
    "    lambda x: x[\"start_positions\"] < tokenizer.model_max_length\n",
    ")\n",
    "processed_dataset = processed_dataset.filter(\n",
    "    lambda x: x[\"end_positions\"] < tokenizer.model_max_length\n",
    ")\n",
    "print(dataset)\n",
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30aba3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer, padding=\"longest\")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"question-answering\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    eval_steps=250,\n",
    "    logging_steps=250,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    data_collator=collator,\n",
    "    train_dataset=processed_dataset[\"train\"].select(range(10000)),\n",
    "    eval_dataset=processed_dataset[\"validation\"].select(range(100))\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a813f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "context = \"서울은 대한민국의 수도다.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "start_index = outputs[\"start_logits\"].argmax(dim=-1).item()\n",
    "end_index = outputs[\"end_logits\"].argmax(dim=-1).item()\n",
    "predicted_ids = inputs[\"input_ids\"][0][start_index : end_index]\n",
    "predicted_text = tokenizer.decode(predicted_ids)\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5898add",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "\n",
    "metric = evaluator(\"question-answering\")\n",
    "results = metric.compute(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    data=processed_dataset[\"validation\"].select(range(100)),\n",
    "    id_column=\"guid\",\n",
    "    question_column=\"question\",\n",
    "    context_column=\"context\",\n",
    "    label_column=\"answers\"\n",
    ")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
