{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eaffd0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from transformers import Owlv2Processor, Owlv2ForObjectDetection\n",
    "\n",
    "model_name = \"google/owlv2-base-patch16\"\n",
    "processor = Owlv2Processor.from_pretrained(model_name)\n",
    "model = Owlv2ForObjectDetection.from_pretrained(model_name)\n",
    "\n",
    "dataset = load_dataset(\"Francesco/animals-ij5d2\")\n",
    "print(dataset)\n",
    "print(dataset[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f322644",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "images = dataset[\"test\"][\"image\"][:2]\n",
    "categories = dataset[\"test\"].features[\"objects\"].feature[\"category\"].names\n",
    "labels = [categories] * len(images)\n",
    "inputs = processor(text=labels, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "print(images)\n",
    "print(labels)\n",
    "print(\"input_ids :\", inputs[\"input_ids\"])\n",
    "print(\"attention_mask :\", inputs[\"attention_mask\"])\n",
    "print(\"pixel_values :\", inputs[\"pixel_values\"])\n",
    "print(\"image_shape :\", inputs[\"pixel_values\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc753ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs.to(device))\n",
    "    \n",
    "print(outputs.keys())\n",
    "print(\"logits :\", outputs.logits.shape)\n",
    "print(\"objectness_logits :\", outputs.objectness_logits.shape)\n",
    "print(\"pred_boxes :\", outputs.pred_boxes.shape)\n",
    "print(\"class_embeds :\", outputs.class_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a01f43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "shape = [dataset[\"test\"][:2][\"width\"], dataset[\"test\"][:2][\"height\"]]\n",
    "target_sizes = list(map(list, zip(*shape)))\n",
    "detections = processor.post_process_object_detection(\n",
    "    outputs=outputs, threshold=0.5, target_sizes=target_sizes\n",
    ")\n",
    "\n",
    "print(target_sizes)\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07c0bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "for idx, (image, detect) in enumerate(zip(images, detections)):\n",
    "    im = image.copy()\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "\n",
    "    for box, score, label in zip(detect[\"boxes\"], detect[\"scores\"], detect[\"labels\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        draw.rectangle(box, outline=\"red\", width=3)\n",
    "        \n",
    "        label_text = f\"{labels[idx][label]}: {round(score.item(), 3)}\"\n",
    "        draw.text((box[0], box[1]), label_text, fill=\"red\", font=font)\n",
    "\n",
    "    plt.imshow(im)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c46ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968261fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_coco_annotations(dataset):\n",
    "    annotations = []\n",
    "    for data in dataset:\n",
    "        image_id = int(data[\"image_id\"])\n",
    "        objects = data[\"objects\"]\n",
    "        for idx in range(len(objects[\"id\"])):\n",
    "            annotations.append(\n",
    "                {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": int(objects[\"category\"][idx]),\n",
    "                    \"bbox\": [float(coord) for coord in objects[\"bbox\"][idx]],\n",
    "                    \"area\": float(objects[\"area\"][idx]),\n",
    "                    \"id\": int(objects[\"id\"][idx]),\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "            )\n",
    "    return annotations\n",
    "\n",
    "coco_annotations = get_coco_annotations(dataset[\"test\"])\n",
    "coco_annotation_format = {\n",
    "    \"annotations\": coco_annotations,\n",
    "    \"images\": [{\"id\": int(data[\"image_id\"])} for data in dataset[\"test\"]],\n",
    "    \"categories\": [{\"id\": i, \"name\": name} for i, name in enumerate(categories)]\n",
    "}\n",
    "print(len(coco_annotations))\n",
    "print(coco_annotation_format[\"annotations\"][0])\n",
    "print(coco_annotation_format[\"images\"][0])\n",
    "print(coco_annotation_format[\"categories\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab7984",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset[\"test\"],\n",
    "    batch_size=2,\n",
    "    collate_fn=lambda batch: (\n",
    "        [item[\"image\"] for item in batch],\n",
    "        [list(item[\"image\"].size) for item in batch],\n",
    "        [item[\"image_id\"] for item in batch],\n",
    "        [item[\"objects\"] for item in batch]\n",
    "    )\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, target_sizes, image_ids, objects in dataloader:\n",
    "        input_labels = [categories] * len(images)\n",
    "        inputs = processor(images=images, text=input_labels, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs.to(device))\n",
    "        detections = processor.post_process_object_detection(\n",
    "            outputs=outputs, threshold=0.3, target_sizes=target_sizes\n",
    "        )\n",
    "\n",
    "        for batch_idx, detection in enumerate(detections):\n",
    "            category_ids = detection[\"labels\"].cpu().numpy().tolist()\n",
    "            scores = detection[\"scores\"].cpu().numpy().tolist()\n",
    "            boxes = detection[\"boxes\"].cpu().numpy()\n",
    "\n",
    "            boxes[:, 2:4] -= boxes[:, :2]\n",
    "            boxes = boxes.tolist()\n",
    "\n",
    "            for obj_idx, box in enumerate(boxes):\n",
    "                prediction = {\n",
    "                    \"image_id\": image_ids[batch_idx],\n",
    "                    \"category_id\": category_ids[obj_idx],\n",
    "                    \"bbox\": box,\n",
    "                    \"score\": scores[obj_idx]\n",
    "                }\n",
    "                predictions.append(prediction)\n",
    "\n",
    "print(len(predictions))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda78ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "coco_gt = COCO()\n",
    "coco_gt.dataset = coco_annotation_format\n",
    "coco_gt.createIndex()\n",
    "\n",
    "coco_dt = coco_gt.loadRes(predictions)\n",
    "\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
